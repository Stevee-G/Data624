---
title: "Data 624 Project 2"
authors: "Michael Robinson and Steven Gonzalez"
date: "5/18/2025"
output:
  html_document: default
  pdf_document: default
---
```{r setup, message=FALSE, warning=FALSE, include=FALSE}
library(caret)
library(corrplot)
library(DMwR2)
library(e1071)
library(gbm)
library(ggplot2)
library(kernlab)
library(knitr)
library(nnet)
library(openxlsx)
library(randomForest)
library(readxl)
library(tidyverse)
library(VIM)

set.seed(123)
```
## Prompt
This is role playing. I am your new boss. I am in charge of production at ABC Beverage and you are a team of data scientists reporting to me. My leadership has told me that new regulations are requiring us to understand our manufacturing process, the predictive factors and be able to report to them our predictive model of PH.

Please use the historical data set I am providing. Build and report the factors in BOTH a technical and non-technical report. I like to use Word and Excel. Please provide your non-technical report in a business friendly readable document and your predictions in an Excel readable format. The technical report should show clearly the models you tested and how you selected your final approach.

## Approach


## Data Exploration


### Load and View Data
```{r message=FALSE, warning=FALSE}
training <- read.csv("https://raw.githubusercontent.com/Stevee-G/Data624/refs/heads/main/Project2/TrainingData.csv")
testing <- read.csv("https://raw.githubusercontent.com/Stevee-G/Data624/refs/heads/main/Project2/TestData.csv")

str(training)
str(testing)
```

### Assess PH Distributions by Brand Code
```{r message=FALSE, warning=FALSE}
training %>% 
  ggplot() + 
  aes(x = PH) + 
  geom_histogram(bins= 50) + 
  facet_wrap(~ Brand.Code, scales = "free")

training %>% 
  ggplot() + 
  aes(x = PH) + 
  geom_boxplot() + 
  facet_wrap(~ Brand.Code, scales = "free")
```

### Assess Predictor Distributions, Skewness, and Relationships
```{r message=FALSE, warning=FALSE}
training %>% 
  select(where(is.numeric))%>% 
  gather() %>% 
  filter(!is.na(value)) %>% 
  ggplot(aes(value)) +
  geom_histogram(bins = 50) +
  facet_wrap(~ key, scales = "free")

training %>%
  select(where(is.numeric))%>%
  gather() %>%
  filter(!is.na(value)) %>% 
  ggplot(aes(value)) +
  geom_boxplot() +
  facet_wrap(~key, scales = "free")

training_cor <- cor(training %>% 
                      select(where(is.numeric)),
                    use = "complete.obs")
corrplot(training_cor)

testing %>%
  select(where(is.numeric)) %>%
  gather() %>% 
  filter(!is.na(value)) %>% 
  ggplot(aes(value)) +
  geom_histogram(bins = 50) +
  facet_wrap(~ key, scales = "free")

testing %>%
  select(where(is.numeric)) %>%
  gather() %>%
  filter(!is.na(value)) %>% 
  ggplot(aes(value)) +
  geom_boxplot() +
  facet_wrap(~key, scales = "free")

testing_cor <- cor(testing %>% 
                      select(where(is.numeric)),
                    use = "complete.obs")
corrplot(testing_cor)
```

## Data Preparation

### Address Missing Data
```{r message=FALSE, warning=FALSE}
training %>%
  select(c(2:33)) %>% 
  summarize_all(funs(sum(is.na(.)))) %>% 
  pivot_longer(everything(),
               names_to = 'Predictor',
               values_to = 'Number of Missing Values')

training <- kNN(training, k = 5) %>% 
  select(c(1:33))

training %>%
  select(c(2:33)) %>% 
  summarize_all(funs(sum(is.na(.)))) %>% 
  pivot_longer(everything(),
               names_to = 'Predictor',
               values_to = 'Number of Missing Values')
```

### Address Degenerate Variables
```{r message=FALSE, warning=FALSE}
nearZeroVar(training %>% 
              select(c(2:33)), name = TRUE)
training <- training %>% 
  select(-Hyd.Pressure1)
```

### Address Highly Correlated Variables
```{r message=FALSE, warning=FALSE}
findCorrelation(testing_cor, cutoff = 0.9, names = TRUE)
training <- training %>% 
  select(-c(Balling, Hyd.Pressure3, Alch.Rel, Density, Filler.Level))
```

## Assessing Models

### Training Data Partitioning
```{r message=FALSE, warning=FALSE}
X <- training[, !names(training) %in% c("PH")]
y <- training$PH

set.seed(123)

trainIndex <- createDataPartition(y, p = 0.8, list = FALSE)
X_train <- X[trainIndex, ]
X_test <- X[-trainIndex, ]
y_train <- y[trainIndex]
y_test <- y[-trainIndex]
```

### Hyperparameter Tuning Setup
```{r message=FALSE, warning=FALSE}
ctrl <- trainControl(
  method = "cv",           
  number = 10,          
  repeats = 3,            
  search = "grid",       
  verboseIter = FALSE,    
  savePredictions = "final"
)
ctrl_simple <- trainControl(
  method = "cv",
  number = 5,            
  search = "grid",
  verboseIter = FALSE,
  savePredictions = "final"
)
```

### Decision Tree Model 
```{r message=FALSE, warning=FALSE}
dt_grid <- expand.grid(
  cp = seq(0.001, 0.1, by = 0.01)  
)
dt_model <- train(
  x = X_train, 
  y = y_train,
  method = "rpart",
  trControl = ctrl,
  tuneGrid = dt_grid,
  metric = "RMSE"
)
print(dt_model)
plot(dt_model, main = "Decision Tree Hyperparameter Tuning")
dt_pred <- predict(dt_model, X_test)
cat("Decision Tree training complete.\n")
```

### Linear Regression Model 
```{r message=FALSE, warning=FALSE}
linear_model <- train(
  x = X_train, 
  y = y_train,
  method = "lm",
  trControl = ctrl,
  preProcess = c("center", "scale"),  
  metric = "RMSE"
)
print(linear_model)
linear_pred <- predict(linear_model, X_test)
```

### Neural Network Model with Tuning
```{r message=FALSE, warning=FALSE}
nn_grid <- expand.grid(
  size = c(5, 10, 15, 20),     
  decay = c(0, 0.001, 0.01, 0.1)  
)
nn_model <- train(
  x = X_train, 
  y = y_train,
  method = "nnet",
  trControl = ctrl_simple,
  tuneGrid = nn_grid,
  linout = TRUE,
  trace = FALSE,
  maxit = 1000,
  metric = "RMSE"
)
print(nn_model)
plot(nn_model, main = "Neural Network Hyperparameter Tuning")
nn_pred <- predict(nn_model, X_test)
```

### Random Forest Model with Tuning
```{r message=FALSE, warning=FALSE}
rf_grid <- expand.grid(
  mtry = c(2, 4, 6, 8, 10, 12) 
)
rf_model <- train(
  x = X_train, 
  y = y_train,
  method = "rf",
  trControl = ctrl,
  tuneGrid = rf_grid,
  ntree = 500,   
  importance = TRUE,
  metric = "RMSE"
)
print(rf_model)
plot(rf_model, main = "Random Forest Hyperparameter Tuning")
rf_pred <- predict(rf_model, X_test)
```

### Support Vector Machine with Tuning
```{r message=FALSE, warning=FALSE, error=TRUE}
svm_grid <- expand.grid(
  sigma = c(0.01, 0.05, 0.1, 0.5, 1),    
  C = c(0.1, 1, 10, 100, 1000)          
)
svm_model <- train(
  x = X_train, 
  y = y_train,
  method = "svmRadial",
  trControl = ctrl_simple,
  tuneGrid = svm_grid,
  metric = "RMSE"
)
print(svm_model)
plot(svm_model, main = "SVM Hyperparameter Tuning")
svm_pred <- predict(svm_model, X_test)
```

## Model Performance Evaluation and Visualization
```{r message=FALSE, warning=FALSE}
model_results <- data.frame(
  Model = c("Linear Regression", "Decision Tree", "Random Forest", "Support Vector Machine", "Neural Network"),
  RMSE = c(postResample(linear_pred, y_test)[1],
           postResample(dt_pred, y_test)[1],
           postResample(rf_pred, y_test)[1],
           postResample(svm_pred, y_test)[1],
           postResample(nn_pred, y_test)[1]),
  Rsquared = c(postResample(linear_pred, y_test)[2],
               postResample(dt_pred, y_test)[2],
               postResample(rf_pred, y_test)[2],
               postResample(svm_pred, y_test)[2],
               postResample(nn_pred, y_test)[2])
)
print(model_results)

plot1 <- ggplot(model_results, aes(x=Model, y=RMSE, fill=Model)) +
  geom_bar(stat="identity", width=0.6) +
  labs(title="Model RMSE Comparison", y="RMSE", x="Model") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
plot2 <- ggplot(model_results, aes(x=Model, y=Rsquared, fill=Model)) +
  geom_bar(stat="identity", width=0.6) +
  labs(title="Model R-Squared Comparison", y="R-Squared", x="Model") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
print(plot1)
print(plot2)
```

## Prediction and File Export
```{r }
testing <- testing %>%
  select(-c(PH, Balling, Hyd.Pressure1, Hyd.Pressure3, Alch.Rel, Density, Filler.Level)) %>% 
  mutate(PH = "")

pred <- predict(dt_model, testing)

testing$PH <- pred

excel <- createWorkbook()
addWorksheet(excel, "PH Prediction")
writeData(excel, sheet = "PH Prediction", testing)
saveWorkbook(excel, "TestData.xlsx", overwrite = TRUE)
```

## Conclusion





